{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f378e6-907b-40fb-8270-f3312ebfc898",
   "metadata": {},
   "source": [
    "### Load reqs and start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "698c5a99-2612-44df-aabb-d8c72735e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../src/python\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3972d090-eb44-4be8-9226-deafedc21f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iceberg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd \"/home/iceberg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c2f769-dfdb-4a01-bc77-bfa520ce62b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/iceberg\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25done\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.12 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (0.19.2)\n",
      "Requirement already satisfied: pytest>=8.0 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (8.4.2)\n",
      "Requirement already satisfied: pydantic>=2.6 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (2.10.6)\n",
      "Requirement already satisfied: chispa>=0.10 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (0.11.1)\n",
      "Requirement already satisfied: rich>=13.7 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (13.9.4)\n",
      "Requirement already satisfied: pyspark>=3.4 in /opt/spark/python (from customer_transaction_etl==0.1.0) (3.5.5)\n",
      "Requirement already satisfied: prettytable<4.0.0,>=3.10.2 in /usr/local/lib/python3.10/site-packages (from chispa>=0.10->customer_transaction_etl==0.1.0) (3.15.1)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.6->customer_transaction_etl==0.1.0) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.6->customer_transaction_etl==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.6->customer_transaction_etl==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/site-packages (from pyspark>=3.4->customer_transaction_etl==0.1.0) (0.10.9.7)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (24.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=13.7->customer_transaction_etl==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/site-packages (from typer>=0.12->customer_transaction_etl==0.1.0) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer>=0.12->customer_transaction_etl==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7->customer_transaction_etl==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prettytable<4.0.0,>=3.10.2->chispa>=0.10->customer_transaction_etl==0.1.0) (0.2.13)\n",
      "Building wheels for collected packages: customer_transaction_etl\n",
      "  Building editable for customer_transaction_etl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for customer_transaction_etl: filename=customer_transaction_etl-0.1.0-0.editable-py3-none-any.whl size=1441 sha256=65c27dcae07bd9abb8fe071d05821190427c6651a6227da5173a3f9b6d754929\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-61bscaoi/wheels/47/e4/18/3729c1b70e0dfec9a6b23d35b4183f467ede935f2336901bfb\n",
      "Successfully built customer_transaction_etl\n",
      "Installing collected packages: customer_transaction_etl\n",
      "  Attempting uninstall: customer_transaction_etl\n",
      "    Found existing installation: customer_transaction_etl 0.1.0\n",
      "    Uninstalling customer_transaction_etl-0.1.0:\n",
      "      Successfully uninstalled customer_transaction_etl-0.1.0\n",
      "Successfully installed customer_transaction_etl-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e /home/iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5342a7c-3e1d-47ce-991e-30b4ec820083",
   "metadata": {},
   "source": [
    "## Starting the Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7800506d-0cce-4195-8e5f-17f5fdc45e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 18:15:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from customer_transaction_etl.session import build_spark\n",
    "spark = build_spark(\"data-exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5601fee3-8ab6-4d1d-8503-5ff685e7f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28-09-2025\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today().strftime('%d-%m-%Y'))\n",
    "today=datetime.today().strftime('%d-%m-%Y')\n",
    "\n",
    "from customer_transaction_etl.config import Paths\n",
    "ingest_date = \"2025-09-25\"  # or today \n",
    "source_root = \"/home/iceberg/data/raw/customer_data_ingest\"  # <- adjust if needed\n",
    "raw_glob = f\"{source_root}/ingest_date={ingest_date}/*.json\"\n",
    "#raw_glob = os.path.join(paths.raw, f\"ingest_date={ingest_date}\", \"*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17580470-6db3-4595-9161-4774384aad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /home/iceberg/data/raw/customer_data_ingest/ingest_date=2025-09-25/*.json\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- products: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- price: string (nullable = true)\n",
      " |    |    |-- product_id: string (nullable = true)\n",
      " |    |    |-- quantity: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      "\n",
      "+-----------+--------+---------------------------------------------------------------+-------------+\n",
      "|customer_id|order_id|products                                                       |purchase_date|\n",
      "+-----------+--------+---------------------------------------------------------------+-------------+\n",
      "|C001       |O001    |[{Product A, 10,99, P001, 2,00}, { Product B,  5.99 , P002, 1}]| 2023-01-01  |\n",
      "|C002       |O002    |[{Product A, 10,99, P001, 3,00}, {Product C, 7.99, P003,  2}]  |2023-01-02   |\n",
      "|C003       |O003    |[{Product B, 5,99, P002,  1}, {Product C,  7,99 , P003, 4,00}] |2023-01-03   |\n",
      "+-----------+--------+---------------------------------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading:\", raw_glob)\n",
    "df_raw = spark.read.json(raw_glob, multiLine=True)\n",
    "\n",
    "df_raw.printSchema()\n",
    "df_raw.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14b5b6-fbcd-4478-9518-433b96b69832",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d2d3c-273c-4128-97a2-f4366bd9f6fe",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> ExplodeToLines </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6972090c-c632-48f9-bf2d-b224bb45e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|O001    |C001       | 2023-01-01  |P001      |Product A   |2,00    |10,99 |\n",
      "|O001    |C001       | 2023-01-01  |P002      | Product B  |1       | 5.99 |\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |3,00    |10,99 |\n",
      "|O002    |C002       |2023-01-02   |P003      |Product C   | 2      |7.99  |\n",
      "|O003    |C003       |2023-01-03   |P002      |Product B   | 1      |5,99  |\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |4,00    | 7,99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from customer_transaction_etl.steps import ExplodeToLines\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "from decimal import Decimal\n",
    "\n",
    "explode = ExplodeToLines()\n",
    "\n",
    "df_lines = explode.transform(df_raw)\n",
    "\n",
    "df_lines.printSchema()\n",
    "df_lines.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834b253-9d20-43a5-bf5d-9d54188981e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### How it will look without calling the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "308e762d-9a1f-453a-85a5-a3f7cdd911ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- products: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- price: string (nullable = true)\n",
      " |    |    |-- product_id: string (nullable = true)\n",
      " |    |    |-- quantity: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- item: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- price: string (nullable = true)\n",
      " |    |-- product_id: string (nullable = true)\n",
      " |    |-- quantity: string (nullable = true)\n",
      "\n",
      "+-----------+--------+--------------------+-------------+--------------------+\n",
      "|customer_id|order_id|            products|purchase_date|                item|\n",
      "+-----------+--------+--------------------+-------------+--------------------+\n",
      "|       C001|    O001|[{Product A, 10,9...|   2023-01-01|{Product A, 10,99...|\n",
      "|       C001|    O001|[{Product A, 10,9...|   2023-01-01|{ Product B,  5.9...|\n",
      "|       C002|    O002|[{Product A, 10,9...|  2023-01-02 |{Product A, 10,99...|\n",
      "|       C002|    O002|[{Product A, 10,9...|  2023-01-02 |{Product C, 7.99,...|\n",
      "|       C003|    O003|[{Product B, 5,99...|   2023-01-03|{Product B, 5,99,...|\n",
      "|       C003|    O003|[{Product B, 5,99...|   2023-01-03|{Product C,  7,99...|\n",
      "+-----------+--------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "exploded_exmp = df_raw.withColumn(\"item\", F.explode(\"products\"))\n",
    "\n",
    "exploded_exmp.printSchema()\n",
    "exploded_exmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a05e097-01e1-47e0-8c81-9a34789abbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity| price|\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|    O001|       C001|   2023-01-01|      P001|   Product A|    2,00| 10,99|\n",
      "|    O001|       C001|   2023-01-01|      P002|   Product B|       1| 5.99 |\n",
      "|    O002|       C002|  2023-01-02 |      P001|   Product A|    3,00| 10,99|\n",
      "|    O002|       C002|  2023-01-02 |      P003|   Product C|       2|  7.99|\n",
      "|    O003|       C003|   2023-01-03|      P002|   Product B|       1|  5,99|\n",
      "|    O003|       C003|   2023-01-03|      P003|   Product C|    4,00| 7,99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        lines_exmp = (\n",
    "            exploded_exmp\n",
    "            .select(\n",
    "                F.col(\"order_id\"),\n",
    "                F.col(\"customer_id\"),\n",
    "                F.col(\"purchase_date\"),\n",
    "                F.col(\"item.product_id\").alias(\"product_id\"),\n",
    "                F.col(\"item.name\").alias(\"product_name\"),\n",
    "                F.col(\"item.quantity\").alias(\"quantity\"),\n",
    "                F.col(\"item.price\").alias(\"price\"),\n",
    "            )\n",
    "        )   \n",
    "\n",
    "lines_exmp.printSchema()\n",
    "lines_exmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c597c-8e8d-4015-9bfa-b7926f31c99c",
   "metadata": {},
   "source": [
    "#### End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf6cfe-baef-4b29-9a6c-8c298f49e1f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f9ed49-ecf0-4ad5-9401-9225f1e88dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected line count: 6  | Actual: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Number of line rows should equal sum of products array sizes per order\n",
    "expected_count = (df_raw\n",
    "    .select(F.size(F.col(\"products\")).alias(\"n\"))\n",
    "    .agg(F.sum(\"n\").alias(\"sum_n\"))\n",
    "    .collect()[0][\"sum_n\"])\n",
    "\n",
    "actual_count = df_lines.count()\n",
    "\n",
    "print(\"Expected line count:\", expected_count, \" | Actual:\", actual_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5301fa45-b355-4297-bca2-d2768428c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['order_id', 'customer_id', 'purchase_date', 'product_id', 'product_name', 'quantity', 'price']\n",
      "+--------+----------+\n",
      "|order_id|line_count|\n",
      "+--------+----------+\n",
      "|    O002|         2|\n",
      "|    O001|         2|\n",
      "|    O003|         2|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) No columns lost accidentally\n",
    "print(\"Columns:\", df_lines.columns)\n",
    "\n",
    "# 3) Quick peek grouped by order to ensure row multiplication looks right\n",
    "df_lines.groupBy(\"order_id\").agg(F.count(\"*\").alias(\"line_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3542-a258-4f7f-96b0-ce9d2afe7684",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> CleanseAndCast</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3709a43-2292-4f48-b9ab-5e19388178cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_transaction_etl.steps import CleanseAndCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1fa43dd-2233-467c-bb4c-2f55bca289f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: date (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: decimal(10,2) (nullable = true)\n",
      "\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price|\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|O001    |C001       |2023-01-01   |P001      |Product A   |2       |10.99|\n",
      "|O001    |C001       |2023-01-01   |P002      |Product B   |1       |5.99 |\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |3       |10.99|\n",
      "|O002    |C002       |2023-01-02   |P003      |Product C   |2       |7.99 |\n",
      "|O003    |C003       |2023-01-03   |P002      |Product B   |1       |5.99 |\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |4       |7.99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cast_step = CleanseAndCast()\n",
    "df_cast = cast_step.transform(df_lines)  # df_lines is the output from ExplodeToLines\n",
    "\n",
    "df_cast.printSchema()\n",
    "df_cast.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276a5091-cd5f-45dc-905f-3b38b501cf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cast: 6\n",
      "Invalid rows: 0\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price|\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "\n",
      "Non-positive quantities: 0\n",
      "Non-positive prices: 0\n"
     ]
    }
   ],
   "source": [
    "total_rows = df_cast.count()\n",
    "print(\"Rows after cast:\", total_rows)\n",
    "\n",
    "# 1) How many rows failed to parse critical fields (now null)?\n",
    "invalid = df_cast.where(\n",
    "    F.col(\"order_id\").isNull() |\n",
    "    F.col(\"product_id\").isNull() |\n",
    "    F.col(\"purchase_date\").isNull() |\n",
    "    F.col(\"quantity\").isNull() |\n",
    "    F.col(\"price\").isNull()\n",
    ")\n",
    "print(\"Invalid rows:\", invalid.count())\n",
    "invalid.show(truncate=False)\n",
    "\n",
    "# 2) Are any quantities non-positive? (optional business rule)\n",
    "neg_qty = df_cast.where(F.col(\"quantity\") <= 0)\n",
    "print(\"Non-positive quantities:\", neg_qty.count())\n",
    "\n",
    "# 3) Are any prices negative?\n",
    "neg_price = df_cast.where(F.col(\"price\") <= 0)\n",
    "print(\"Non-positive prices:\", neg_price.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f2ad5-9a5c-4572-a4e7-b7ac3762e459",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Check all transformations in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45ff7d62-3a80-41e1-b247-aa2ad09406ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+------+-----------+\n",
      "|order_id|product_id|q_raw|p_raw |d_raw      |\n",
      "+--------+----------+-----+------+-----------+\n",
      "|O001    |P001      |2,00 |10,99 | 2023-01-01|\n",
      "|O001    |P002      |1    | 5.99 | 2023-01-01|\n",
      "|O002    |P001      |3,00 |10,99 |2023-01-02 |\n",
      "|O002    |P003      | 2   |7.99  |2023-01-02 |\n",
      "|O003    |P002      | 1   |5,99  |2023-01-03 |\n",
      "|O003    |P003      |4,00 | 7,99 |2023-01-03 |\n",
      "+--------+----------+-----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lines.select(\n",
    "    \"order_id\",\"product_id\",\n",
    "    F.col(\"quantity\").alias(\"q_raw\"),\n",
    "    F.col(\"price\").alias(\"p_raw\"),\n",
    "    F.col(\"purchase_date\").alias(\"d_raw\")\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f0d20eb-8f3b-4076-a445-24a0535a462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----------+------------+--------+------+------+------+-----+------+------+-----+----------+----------+----+----------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price |q_trim|q_norm|q_dbl|p_trim|p_norm|p_dec|d_trim    |d1        |d2  |d_final   |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+------+------+-----+------+------+-----+----------+----------+----+----------+\n",
      "|O001    |C001       | 2023-01-01  |P001      |Product A   |2,00    |10,99 |2,00  |2.00  |2.0  |10,99 |10.99 |10.99|2023-01-01|2023-01-01|NULL|2023-01-01|\n",
      "|O001    |C001       | 2023-01-01  |P002      | Product B  |1       | 5.99 |1     |1     |1.0  |5.99  |5.99  |5.99 |2023-01-01|2023-01-01|NULL|2023-01-01|\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |3,00    |10,99 |3,00  |3.00  |3.0  |10,99 |10.99 |10.99|2023-01-02|2023-01-02|NULL|2023-01-02|\n",
      "|O002    |C002       |2023-01-02   |P003      |Product C   | 2      |7.99  |2     |2     |2.0  |7.99  |7.99  |7.99 |2023-01-02|2023-01-02|NULL|2023-01-02|\n",
      "|O003    |C003       |2023-01-03   |P002      |Product B   | 1      |5,99  |1     |1     |1.0  |5,99  |5.99  |5.99 |2023-01-03|2023-01-03|NULL|2023-01-03|\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |4,00    | 7,99 |4,00  |4.00  |4.0  |7,99  |7.99  |7.99 |2023-01-03|2023-01-03|NULL|2023-01-03|\n",
      "+--------+-----------+-------------+----------+------------+--------+------+------+------+-----+------+------+-----+----------+----------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm = (df_lines\n",
    "    .withColumn(\"q_trim\", F.trim(\"quantity\"))\n",
    "    .withColumn(\"q_norm\", F.regexp_replace(F.regexp_replace(F.col(\"q_trim\"), r\"\\s+\", \"\"), \",\", \".\"))\n",
    "    .withColumn(\"q_dbl\",  F.col(\"q_norm\").cast(\"double\"))\n",
    "    .withColumn(\"p_trim\", F.trim(\"price\"))\n",
    "    .withColumn(\"p_norm\", F.regexp_replace(F.regexp_replace(F.col(\"p_trim\"), r\"\\s+\", \"\"), \",\", \".\"))\n",
    "    .withColumn(\"p_dec\",  F.col(\"p_norm\").cast(\"decimal(10,2)\"))\n",
    "    .withColumn(\"d_trim\", F.trim(\"purchase_date\"))\n",
    "    .withColumn(\"d1\",     F.to_date(\"d_trim\", \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"d2\",     F.to_date(\"d_trim\", \"dd/MM/yyyy\"))\n",
    "    .withColumn(\"d_final\",F.coalesce(\"d1\",\"d2\"))\n",
    ")\n",
    "norm.select(\"*\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a8dd7-0840-4a93-afb3-54d3b8cdc576",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> DeDuplication step </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcb1930-7097-44ae-bb5e-71537c5d8b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate key groups: 0\n",
      "+--------+----------+---------+\n",
      "|order_id|product_id|row_count|\n",
      "+--------+----------+---------+\n",
      "+--------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_cols = [\"order_id\", \"product_id\"]\n",
    "\n",
    "dups = (df_cast\n",
    "        .groupBy(*key_cols)\n",
    "        .agg(F.count(\"*\").alias(\"row_count\"))\n",
    "        .where(\"row_count > 1\")\n",
    "        .orderBy(F.col(\"row_count\").desc()))\n",
    "\n",
    "print(\"Duplicate key groups:\", dups.count())\n",
    "dups.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e588769-b948-41d3-b7ec-387bc74c4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_transaction_etl.steps import Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abbb0f76-754b-4542-8120-16cd2a00dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 6\n",
      "Rows after: 6 | Removed: 0\n"
     ]
    }
   ],
   "source": [
    "before = df_cast.count()\n",
    "print(\"Rows before:\", before)\n",
    "\n",
    "dedup = Deduplicate(key_cols=[\"order_id\",\"product_id\"], strategy=\"prefer_latest\")\n",
    "df_dedup = dedup.transform(df_cast)\n",
    "\n",
    "after = df_dedup.count()\n",
    "print(\"Rows after:\", after, \"| Removed:\", before - after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ad96fe-78d0-4da3-aaf7-6e22ba7e2c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicate key groups: 0\n"
     ]
    }
   ],
   "source": [
    "# Sanity: ensure no duplicate keys remain\n",
    "check = (df_dedup.groupBy(\"order_id\",\"product_id\")\n",
    "         .agg(F.count(\"*\").alias(\"row_count\"))\n",
    "         .where(\"row_count > 1\"))\n",
    "print(\"Remaining duplicate key groups:\", check.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868733d-3a6b-4a47-9afc-18c559a7f795",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Add Line Amount  </span>\n",
    "### <span style=\"color:silver\"> Silver level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbb68b1-7be3-4000-99eb-5ed07581268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_transaction_etl.steps import WithLineAmount, WithCustomerTotalRevenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0663e7f7-d017-4c51-9d8c-2038daee57fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-----+-----------+\n",
      "|order_id|product_id|quantity|price|line_amount|\n",
      "+--------+----------+--------+-----+-----------+\n",
      "|    O001|      P001|       2|10.99|      21.98|\n",
      "|    O001|      P002|       1| 5.99|       5.99|\n",
      "|    O002|      P001|       3|10.99|      32.97|\n",
      "|    O002|      P003|       2| 7.99|      15.98|\n",
      "|    O003|      P002|       1| 5.99|       5.99|\n",
      "|    O003|      P003|       4| 7.99|      31.96|\n",
      "+--------+----------+--------+-----+-----------+\n",
      "\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: date (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: decimal(10,2) (nullable = true)\n",
      " |-- line_amount: decimal(18,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_amt = WithLineAmount(\"with_line_amount\").transform(df_dedup)\n",
    "df_with_amt.select(\"order_id\",\"product_id\",\"quantity\",\"price\",\"line_amount\").show()\n",
    "df_with_amt.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71af6f2-c50b-4c07-b60e-59a1607c4a40",
   "metadata": {},
   "source": [
    "##### Window Total Revenue per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8676165c-58c6-4618-bfb3-b5671cabe9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------------------+\n",
      "|customer_id|line_amount|customer_total_revenue|\n",
      "+-----------+-----------+----------------------+\n",
      "|       C001|      21.98|                 27.97|\n",
      "|       C001|       5.99|                 27.97|\n",
      "|       C002|      32.97|                 48.95|\n",
      "|       C002|      15.98|                 48.95|\n",
      "|       C003|       5.99|                 37.95|\n",
      "|       C003|      31.96|                 37.95|\n",
      "+-----------+-----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_cust_rev = WithCustomerTotalRevenue().transform(df_with_amt)\n",
    "df_with_cust_rev.select(\"customer_id\",\"line_amount\",\"customer_total_revenue\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babd7a93-8370-4fc2-afb2-30b3063d67e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----------+------------+--------+-----+-----------+----------------------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price|line_amount|customer_total_revenue|\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+-----------+----------------------+\n",
      "|    O001|       C001|   2023-01-01|      P001|   Product A|       2|10.99|      21.98|                 27.97|\n",
      "|    O001|       C001|   2023-01-01|      P002|   Product B|       1| 5.99|       5.99|                 27.97|\n",
      "|    O002|       C002|   2023-01-02|      P001|   Product A|       3|10.99|      32.97|                 48.95|\n",
      "|    O002|       C002|   2023-01-02|      P003|   Product C|       2| 7.99|      15.98|                 48.95|\n",
      "|    O003|       C003|   2023-01-03|      P002|   Product B|       1| 5.99|       5.99|                 37.95|\n",
      "|    O003|       C003|   2023-01-03|      P003|   Product C|       4| 7.99|      31.96|                 37.95|\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+-----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_cust_rev.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41705460-4d3a-4d9e-8e18-208af61e9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer total mismatches: 0\n",
      "Sum(line_amount) overall: 114.87 | Sum of per-customer totals: 114.87\n",
      "Null line_amount rows: 0\n",
      "Null customer_total_revenue rows: 0\n"
     ]
    }
   ],
   "source": [
    "###Sanity\n",
    "\n",
    "# A) Recompute customer totals via groupBy and compare to the window column\n",
    "grp = (df_with_cust_rev\n",
    "       .groupBy(\"customer_id\")\n",
    "       .agg(F.sum(\"line_amount\").alias(\"grp_total\")))\n",
    "\n",
    "chk = (df_with_cust_rev\n",
    "       .select(\"customer_id\",\"customer_total_revenue\")\n",
    "       .dropDuplicates())\n",
    "# Does group by match a distinct prune?\n",
    "joined = chk.join(grp, \"customer_id\")\n",
    "mismatches = joined.where(F.col(\"customer_total_revenue\") != F.col(\"grp_total\"))\n",
    "print(\"Customer total mismatches:\", mismatches.count())\n",
    "\n",
    "# B) Spot-check: sum of line_amount overall should equal sum of the grouped totals\n",
    "total_lines = df_with_cust_rev.agg(F.sum(\"line_amount\").alias(\"s\")).first()[\"s\"]\n",
    "total_grouped = grp.agg(F.sum(\"grp_total\").alias(\"s\")).first()[\"s\"]\n",
    "print(\"Sum(line_amount) overall:\", total_lines, \"| Sum of per-customer totals:\", total_grouped)\n",
    "\n",
    "# C) Sanity: no nulls in critical numeric fields before/after\n",
    "print(\"Null line_amount rows:\", df_with_cust_rev.where(F.col(\"line_amount\").isNull()).count())\n",
    "print(\"Null customer_total_revenue rows:\", df_with_cust_rev.where(F.col(\"customer_total_revenue\").isNull()).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa144a1c-e9d0-454e-a908-3cdfa6952647",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Gold <span style=\"color:blue\"> level Analysis  \n",
    "- Per-product revenue\n",
    "\n",
    "- Top-selling products by revenue\n",
    "\n",
    "- Average Order Value (AOV)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db38c4fd-7fec-44ca-8c59-0b7593d315b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_transaction_etl.aggregates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7f105c-7636-457d-8965-15ebc3cd0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis= df_with_cust_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c07599d-9ca3-4f6d-b46f-014dc3128087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------+--------------+-----------+\n",
      "|product_id|product_name|revenue|total_quantity|order_count|\n",
      "+----------+------------+-------+--------------+-----------+\n",
      "|P001      |Product A   |54.95  |5             |2          |\n",
      "|P003      |Product C   |47.94  |6             |2          |\n",
      "|P002      |Product B   |11.98  |2             |2          |\n",
      "+----------+------------+-------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Per-product revenue (overall)\n",
    "prod_rev = product_revenue(df_analysis, by=\"overall\")\n",
    "prod_rev.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42ef486f-24bb-4137-9956-5e2f525615bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------------+-------+--------------+-----------+\n",
      "|purchase_date|product_id|product_name|revenue|total_quantity|order_count|\n",
      "+-------------+----------+------------+-------+--------------+-----------+\n",
      "|2023-01-01   |P001      |Product A   |21.98  |2             |1          |\n",
      "|2023-01-01   |P002      |Product B   |5.99   |1             |1          |\n",
      "|2023-01-02   |P001      |Product A   |32.97  |3             |1          |\n",
      "|2023-01-02   |P003      |Product C   |15.98  |2             |1          |\n",
      "|2023-01-03   |P003      |Product C   |31.96  |4             |1          |\n",
      "|2023-01-03   |P002      |Product B   |5.99   |1             |1          |\n",
      "+-------------+----------+------------+-------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.b: per-day product revenue\n",
    "prod_rev_daily = product_revenue(df_analysis, by=\"daily\")\n",
    "prod_rev_daily.orderBy(\"purchase_date\", F.desc(\"revenue\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea27eedc-de04-49ad-8adc-c882b82f2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------+--------------+-----------+----+\n",
      "|product_id|product_name|revenue|total_quantity|order_count|rank|\n",
      "+----------+------------+-------+--------------+-----------+----+\n",
      "|P001      |Product A   |54.95  |5             |2          |1   |\n",
      "|P003      |Product C   |47.94  |6             |2          |2   |\n",
      "|P002      |Product B   |11.98  |2             |2          |3   |\n",
      "+----------+------------+-------+--------------+-----------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 18:17:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# 2) Top-N products by revenue\n",
    "topN = top_products_by_revenue(df_analysis, n=5, by=\"overall\")\n",
    "topN.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37f7523f-2ca2-4d26-bc7b-bff62bb6865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------------+\n",
      "|total_revenue|order_count|average_order_value|\n",
      "+-------------+-----------+-------------------+\n",
      "|114.87       |3          |38.29              |\n",
      "+-------------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Average Order Value\n",
    "aov = average_order_value(df_analysis)\n",
    "aov.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407297a-db18-46f9-958e-82a0929461f2",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\"> Write Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb7f841-50e2-4d59-ba78-90406e0433a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurePosixPath('silver')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path,PurePath\n",
    "PurePath(\"silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bca9198-8e65-48c8-861e-4b66dd4a9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_transaction_etl.config import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1410dae2-3eff-475c-b0c3-92fe38ef1994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/gold\n"
     ]
    }
   ],
   "source": [
    "print(Paths.gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0133d0-2b8c-49aa-9357-b48992eac67c",
   "metadata": {},
   "source": [
    "### Write Silver level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72296cab-4c94-4f6c-816a-3acfd3a5d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_with_cust_rev\n",
    " .write\n",
    " .mode(\"overwrite\") #overwrite-by-partition\n",
    " .partitionBy(\"purchase_date\")\n",
    " .parquet(\"/home/iceberg/data/silver/customer_data/order_lines\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af60d6d-2c14-49a5-aa82-dc1f8c66692f",
   "metadata": {},
   "source": [
    "### Write Gold level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1948d50-4af7-4c94-820d-251c8c2316cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "snapshot_date = date.today().isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcda58ef-7e1f-469e-b5d2-608117af35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Product Revenue\n",
    "(prod_rev_daily\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .partitionBy(\"purchase_date\")\n",
    " .parquet(\"/home/iceberg/data/gold/customer_data/product_revenue\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7016f4ae-7767-4661-9aa3-0475fc8a35e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 19:04:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/09/28 19:04:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# Top N (overall) products by Revenue\n",
    "(topN\n",
    " .withColumn(\"snapshot_date\", F.lit(snapshot_date))\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .partitionBy(\"snapshot_date\")\n",
    " .parquet(\"/home/iceberg/data/gold/customer_data/top_products\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f76d3293-ed22-42a7-a393-bda6630eaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Order Value as a snapshot table\n",
    "(aov\n",
    " .withColumn(\"snapshot_date\", F.lit(snapshot_date))\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .partitionBy(\"snapshot_date\")\n",
    " .parquet(\"/home/iceberg/data/gold/customer_data/order_kpis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e858d-c61f-400f-afc4-42c571a78738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
