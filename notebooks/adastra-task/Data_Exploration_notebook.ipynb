{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f378e6-907b-40fb-8270-f3312ebfc898",
   "metadata": {},
   "source": [
    "### Load reqs and start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698c5a99-2612-44df-aabb-d8c72735e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../src/python\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3972d090-eb44-4be8-9226-deafedc21f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iceberg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd \"/home/iceberg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c2f769-dfdb-4a01-bc77-bfa520ce62b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/iceberg\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25done\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.12 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (0.19.2)\n",
      "Requirement already satisfied: pytest>=8.0 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (8.4.2)\n",
      "Requirement already satisfied: pydantic>=2.6 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (2.10.6)\n",
      "Requirement already satisfied: chispa>=0.10 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (0.11.1)\n",
      "Requirement already satisfied: rich>=13.7 in /usr/local/lib/python3.10/site-packages (from customer_transaction_etl==0.1.0) (13.9.4)\n",
      "Requirement already satisfied: pyspark>=3.4 in /opt/spark/python (from customer_transaction_etl==0.1.0) (3.5.5)\n",
      "Requirement already satisfied: prettytable<4.0.0,>=3.10.2 in /usr/local/lib/python3.10/site-packages (from chispa>=0.10->customer_transaction_etl==0.1.0) (3.15.1)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.6->customer_transaction_etl==0.1.0) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.6->customer_transaction_etl==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.6->customer_transaction_etl==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/site-packages (from pyspark>=3.4->customer_transaction_etl==0.1.0) (0.10.9.7)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/site-packages (from pytest>=8.0->customer_transaction_etl==0.1.0) (24.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=13.7->customer_transaction_etl==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/site-packages (from typer>=0.12->customer_transaction_etl==0.1.0) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer>=0.12->customer_transaction_etl==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7->customer_transaction_etl==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prettytable<4.0.0,>=3.10.2->chispa>=0.10->customer_transaction_etl==0.1.0) (0.2.13)\n",
      "Building wheels for collected packages: customer_transaction_etl\n",
      "  Building editable for customer_transaction_etl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for customer_transaction_etl: filename=customer_transaction_etl-0.1.0-0.editable-py3-none-any.whl size=1441 sha256=65c27dcae07bd9abb8fe071d05821190427c6651a6227da5173a3f9b6d754929\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-61bscaoi/wheels/47/e4/18/3729c1b70e0dfec9a6b23d35b4183f467ede935f2336901bfb\n",
      "Successfully built customer_transaction_etl\n",
      "Installing collected packages: customer_transaction_etl\n",
      "  Attempting uninstall: customer_transaction_etl\n",
      "    Found existing installation: customer_transaction_etl 0.1.0\n",
      "    Uninstalling customer_transaction_etl-0.1.0:\n",
      "      Successfully uninstalled customer_transaction_etl-0.1.0\n",
      "Successfully installed customer_transaction_etl-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e /home/iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5342a7c-3e1d-47ce-991e-30b4ec820083",
   "metadata": {},
   "source": [
    "## Starting the Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7800506d-0cce-4195-8e5f-17f5fdc45e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 10:53:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from customer_transaction_etl.session import build_spark\n",
    "spark = build_spark(\"data-exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5601fee3-8ab6-4d1d-8503-5ff685e7f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28-09-2025\n",
      "Reading: /home/iceberg/data/raw/customer_data_ingest/ingest_date=2025-09-25/*.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.today().strftime('%d-%m-%Y'))\n",
    "today=datetime.today().strftime('%d-%m-%Y')\n",
    "\n",
    "from customer_transaction_etl.config import Paths\n",
    "ingest_date = \"2025-09-25\"  # or today \n",
    "source_root = \"/home/iceberg/data/raw/customer_data_ingest\"  # <- adjust if needed\n",
    "raw_glob = f\"{source_root}/ingest_date={ingest_date}/*.json\"\n",
    "#raw_glob = os.path.join(paths.raw, f\"ingest_date={ingest_date}\", \"*.json\")\n",
    "print(\"Reading:\", raw_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17580470-6db3-4595-9161-4774384aad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /home/iceberg/data/raw/customer_data_ingest/ingest_date=2025-09-25/*.json\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- products: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- price: string (nullable = true)\n",
      " |    |    |-- product_id: string (nullable = true)\n",
      " |    |    |-- quantity: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      "\n",
      "+-----------+--------+---------------------------------------------------------------+-------------+\n",
      "|customer_id|order_id|products                                                       |purchase_date|\n",
      "+-----------+--------+---------------------------------------------------------------+-------------+\n",
      "|C001       |O001    |[{Product A, 10,99, P001, 2,00}, { Product B,  5.99 , P002, 1}]| 2023-01-01  |\n",
      "|C002       |O002    |[{Product A, 10,99, P001, 3,00}, {Product C, 7.99, P003,  2}]  |2023-01-02   |\n",
      "|C003       |O003    |[{Product B, 5,99, P002,  1}, {Product C,  7,99 , P003, 4,00}] |2023-01-03   |\n",
      "+-----------+--------+---------------------------------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading:\", raw_glob)\n",
    "df_raw = spark.read.json(raw_glob, multiLine=True)\n",
    "\n",
    "df_raw.printSchema()\n",
    "df_raw.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14b5b6-fbcd-4478-9518-433b96b69832",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d2d3c-273c-4128-97a2-f4366bd9f6fe",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> ExplodeToLines </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6972090c-c632-48f9-bf2d-b224bb45e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|O001    |C001       | 2023-01-01  |P001      |Product A   |2,00    |10,99 |\n",
      "|O001    |C001       | 2023-01-01  |P002      | Product B  |1       | 5.99 |\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |3,00    |10,99 |\n",
      "|O002    |C002       |2023-01-02   |P003      |Product C   | 2      |7.99  |\n",
      "|O003    |C003       |2023-01-03   |P002      |Product B   | 1      |5,99  |\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |4,00    | 7,99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from customer_transaction_etl.steps import ExplodeToLines\n",
    "\n",
    "explode = ExplodeToLines()\n",
    "\n",
    "df_lines = explode.transform(df_raw)\n",
    "\n",
    "df_lines.printSchema()\n",
    "df_lines.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834b253-9d20-43a5-bf5d-9d54188981e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### How it will look without calling the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "308e762d-9a1f-453a-85a5-a3f7cdd911ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- products: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- price: string (nullable = true)\n",
      " |    |    |-- product_id: string (nullable = true)\n",
      " |    |    |-- quantity: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- item: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- price: string (nullable = true)\n",
      " |    |-- product_id: string (nullable = true)\n",
      " |    |-- quantity: string (nullable = true)\n",
      "\n",
      "+-----------+--------+--------------------+-------------+--------------------+\n",
      "|customer_id|order_id|            products|purchase_date|                item|\n",
      "+-----------+--------+--------------------+-------------+--------------------+\n",
      "|       C001|    O001|[{Product A, 10,9...|   2023-01-01|{Product A, 10,99...|\n",
      "|       C001|    O001|[{Product A, 10,9...|   2023-01-01|{ Product B,  5.9...|\n",
      "|       C002|    O002|[{Product A, 10,9...|  2023-01-02 |{Product A, 10,99...|\n",
      "|       C002|    O002|[{Product A, 10,9...|  2023-01-02 |{Product C, 7.99,...|\n",
      "|       C003|    O003|[{Product B, 5,99...|   2023-01-03|{Product B, 5,99,...|\n",
      "|       C003|    O003|[{Product B, 5,99...|   2023-01-03|{Product C,  7,99...|\n",
      "+-----------+--------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "exploded_exmp = df_raw.withColumn(\"item\", F.explode(\"products\"))\n",
    "\n",
    "exploded_exmp.printSchema()\n",
    "exploded_exmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a05e097-01e1-47e0-8c81-9a34789abbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity| price|\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "|    O001|       C001|   2023-01-01|      P001|   Product A|    2,00| 10,99|\n",
      "|    O001|       C001|   2023-01-01|      P002|   Product B|       1| 5.99 |\n",
      "|    O002|       C002|  2023-01-02 |      P001|   Product A|    3,00| 10,99|\n",
      "|    O002|       C002|  2023-01-02 |      P003|   Product C|       2|  7.99|\n",
      "|    O003|       C003|   2023-01-03|      P002|   Product B|       1|  5,99|\n",
      "|    O003|       C003|   2023-01-03|      P003|   Product C|    4,00| 7,99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        lines_exmp = (\n",
    "            exploded_exmp\n",
    "            .select(\n",
    "                F.col(\"order_id\"),\n",
    "                F.col(\"customer_id\"),\n",
    "                F.col(\"purchase_date\"),\n",
    "                F.col(\"item.product_id\").alias(\"product_id\"),\n",
    "                F.col(\"item.name\").alias(\"product_name\"),\n",
    "                F.col(\"item.quantity\").alias(\"quantity\"),\n",
    "                F.col(\"item.price\").alias(\"price\"),\n",
    "            )\n",
    "        )   \n",
    "\n",
    "lines_exmp.printSchema()\n",
    "lines_exmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c597c-8e8d-4015-9bfa-b7926f31c99c",
   "metadata": {},
   "source": [
    "#### End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf6cfe-baef-4b29-9a6c-8c298f49e1f2",
   "metadata": {},
   "source": [
    "#### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1f9ed49-ecf0-4ad5-9401-9225f1e88dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected line count: 6  | Actual: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Number of line rows should equal sum of products array sizes per order\n",
    "expected_count = (df_raw\n",
    "    .select(F.size(F.col(\"products\")).alias(\"n\"))\n",
    "    .agg(F.sum(\"n\").alias(\"sum_n\"))\n",
    "    .collect()[0][\"sum_n\"])\n",
    "\n",
    "actual_count = df_lines.count()\n",
    "\n",
    "print(\"Expected line count:\", expected_count, \" | Actual:\", actual_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5301fa45-b355-4297-bca2-d2768428c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['order_id', 'customer_id', 'purchase_date', 'product_id', 'product_name', 'quantity', 'price']\n",
      "+--------+----------+\n",
      "|order_id|line_count|\n",
      "+--------+----------+\n",
      "|    O002|         2|\n",
      "|    O001|         2|\n",
      "|    O003|         2|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) No columns lost accidentally\n",
    "print(\"Columns:\", df_lines.columns)\n",
    "\n",
    "# 3) Quick peek grouped by order to ensure row multiplication looks right\n",
    "df_lines.groupBy(\"order_id\").agg(F.count(\"*\").alias(\"line_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3542-a258-4f7f-96b0-ce9d2afe7684",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> CleanseAndCast</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3709a43-2292-4f48-b9ab-5e19388178cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_transaction_etl.steps import CleanseAndCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1fa43dd-2233-467c-bb4c-2f55bca289f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: decimal(10,2) (nullable = true)\n",
      "\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price|\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|O001    |C001       | 2023-01-01  |P001      |Product A   |NULL    |10.99|\n",
      "|O001    |C001       | 2023-01-01  |P002      |Product B   |1       |5.99 |\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |NULL    |10.99|\n",
      "|O002    |C002       |2023-01-02   |P003      |Product C   |2       |7.99 |\n",
      "|O003    |C003       |2023-01-03   |P002      |Product B   |1       |5.99 |\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |NULL    |7.99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cast_step = CleanseAndCast()\n",
    "df_cast = cast_step.transform(df_lines)  # df_lines is the output from ExplodeToLines\n",
    "\n",
    "df_cast.printSchema()\n",
    "df_cast.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "276a5091-cd5f-45dc-905f-3b38b501cf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cast: 6\n",
      "Invalid rows: 3\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price|\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "|O001    |C001       | 2023-01-01  |P001      |Product A   |NULL    |10.99|\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |NULL    |10.99|\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |NULL    |7.99 |\n",
      "+--------+-----------+-------------+----------+------------+--------+-----+\n",
      "\n",
      "Non-positive quantities: 0\n",
      "Non-positive prices: 0\n"
     ]
    }
   ],
   "source": [
    "total_rows = df_cast.count()\n",
    "print(\"Rows after cast:\", total_rows)\n",
    "\n",
    "# 1) How many rows failed to parse critical fields (now null)?\n",
    "invalid = df_cast.where(\n",
    "    F.col(\"order_id\").isNull() |\n",
    "    F.col(\"product_id\").isNull() |\n",
    "    F.col(\"purchase_date\").isNull() |\n",
    "    F.col(\"quantity\").isNull() |\n",
    "    F.col(\"price\").isNull()\n",
    ")\n",
    "print(\"Invalid rows:\", invalid.count())\n",
    "invalid.show(truncate=False)\n",
    "\n",
    "# 2) Are any quantities non-positive? (optional business rule)\n",
    "neg_qty = df_cast.where(F.col(\"quantity\") <= 0)\n",
    "print(\"Non-positive quantities:\", neg_qty.count())\n",
    "\n",
    "# 3) Are any prices negative?\n",
    "neg_price = df_cast.where(F.col(\"price\") <= 0)\n",
    "print(\"Non-positive prices:\", neg_price.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce87a6e4-da43-4429-945d-2937a68a43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+\n",
      "|order_id|product_id|quantity|\n",
      "+--------+----------+--------+\n",
      "|O001    |P001      |2,00    |\n",
      "|O001    |P002      |1       |\n",
      "|O002    |P001      |3,00    |\n",
      "|O002    |P003      | 2      |\n",
      "|O003    |P002      | 1      |\n",
      "|O003    |P003      |4,00    |\n",
      "+--------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lines.select(\"order_id\",\"product_id\",\"quantity\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45ff7d62-3a80-41e1-b247-aa2ad09406ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+------+-----------+\n",
      "|order_id|product_id|q_raw|p_raw |d_raw      |\n",
      "+--------+----------+-----+------+-----------+\n",
      "|O001    |P001      |2,00 |10,99 | 2023-01-01|\n",
      "|O001    |P002      |1    | 5.99 | 2023-01-01|\n",
      "|O002    |P001      |3,00 |10,99 |2023-01-02 |\n",
      "|O002    |P003      | 2   |7.99  |2023-01-02 |\n",
      "|O003    |P002      | 1   |5,99  |2023-01-03 |\n",
      "|O003    |P003      |4,00 | 7,99 |2023-01-03 |\n",
      "+--------+----------+-----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_lines.select(\n",
    "    \"order_id\",\"product_id\",\n",
    "    F.col(\"quantity\").alias(\"q_raw\"),\n",
    "    F.col(\"price\").alias(\"p_raw\"),\n",
    "    F.col(\"purchase_date\").alias(\"d_raw\")\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f0d20eb-8f3b-4076-a445-24a0535a462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----------+------------+--------+------+------+------+-----+------+------+-----+----------+----------+----+----------+\n",
      "|order_id|customer_id|purchase_date|product_id|product_name|quantity|price |q_trim|q_norm|q_dbl|p_trim|p_norm|p_dec|d_trim    |d1        |d2  |d_final   |\n",
      "+--------+-----------+-------------+----------+------------+--------+------+------+------+-----+------+------+-----+----------+----------+----+----------+\n",
      "|O001    |C001       | 2023-01-01  |P001      |Product A   |2,00    |10,99 |2,00  |2.00  |2.0  |10,99 |10.99 |10.99|2023-01-01|2023-01-01|NULL|2023-01-01|\n",
      "|O001    |C001       | 2023-01-01  |P002      | Product B  |1       | 5.99 |1     |1     |1.0  |5.99  |5.99  |5.99 |2023-01-01|2023-01-01|NULL|2023-01-01|\n",
      "|O002    |C002       |2023-01-02   |P001      |Product A   |3,00    |10,99 |3,00  |3.00  |3.0  |10,99 |10.99 |10.99|2023-01-02|2023-01-02|NULL|2023-01-02|\n",
      "|O002    |C002       |2023-01-02   |P003      |Product C   | 2      |7.99  |2     |2     |2.0  |7.99  |7.99  |7.99 |2023-01-02|2023-01-02|NULL|2023-01-02|\n",
      "|O003    |C003       |2023-01-03   |P002      |Product B   | 1      |5,99  |1     |1     |1.0  |5,99  |5.99  |5.99 |2023-01-03|2023-01-03|NULL|2023-01-03|\n",
      "|O003    |C003       |2023-01-03   |P003      |Product C   |4,00    | 7,99 |4,00  |4.00  |4.0  |7,99  |7.99  |7.99 |2023-01-03|2023-01-03|NULL|2023-01-03|\n",
      "+--------+-----------+-------------+----------+------------+--------+------+------+------+-----+------+------+-----+----------+----------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm = (df_lines\n",
    "    .withColumn(\"q_trim\", F.trim(\"quantity\"))\n",
    "    .withColumn(\"q_norm\", F.regexp_replace(F.regexp_replace(F.col(\"q_trim\"), r\"\\s+\", \"\"), \",\", \".\"))\n",
    "    .withColumn(\"q_dbl\",  F.col(\"q_norm\").cast(\"double\"))\n",
    "    .withColumn(\"p_trim\", F.trim(\"price\"))\n",
    "    .withColumn(\"p_norm\", F.regexp_replace(F.regexp_replace(F.col(\"p_trim\"), r\"\\s+\", \"\"), \",\", \".\"))\n",
    "    .withColumn(\"p_dec\",  F.col(\"p_norm\").cast(\"decimal(10,2)\"))\n",
    "    .withColumn(\"d_trim\", F.trim(\"purchase_date\"))\n",
    "    .withColumn(\"d1\",     F.to_date(\"d_trim\", \"yyyy-MM-dd\"))\n",
    "    .withColumn(\"d2\",     F.to_date(\"d_trim\", \"dd/MM/yyyy\"))\n",
    "    .withColumn(\"d_final\",F.coalesce(\"d1\",\"d2\"))\n",
    ")\n",
    "norm.select(\"*\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "baac7daa-7335-4e97-a67b-2e8c50c2a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- purchase_date: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c739c-fa5b-4aaa-a130-843fa121fc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
