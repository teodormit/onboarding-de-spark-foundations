# Data Engineering with Apache Spark on AWS (20-Day Learning Plan)

This repository tracks my 20-day intensive learning journey to become proficient in **Apache Spark** and its integration with **AWS Data Engineering services** (S3, Glue, Athena, Redshift), along with **Terraform for IaC**.  
Goal: Prepare for my company's Data Engineering practice assessment and start contributing to Spark-based projects.

---

## ðŸ“‚ Project Structure
data-engineering-spark-aws/
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks for experiments
â”œâ”€â”€ pyspark-scripts/ # Standalone PySpark jobs
â”œâ”€â”€ datasets/ # Practice datasets
â”œâ”€â”€ terraform/ # Infrastructure as Code with Terraform
â”œâ”€â”€ aws-glue-scripts/ # AWS Glue-compatible PySpark jobs
â”œâ”€â”€ docs/ # Notes, cheatsheets, summaries
â””â”€â”€ requirements.txt